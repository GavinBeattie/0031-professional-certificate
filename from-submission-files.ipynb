{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d43a082",
   "metadata": {},
   "source": [
    "# References\n",
    "1 https://archive.ics.uci.edu/dataset/124/cmu+face+images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73865cad",
   "metadata": {},
   "source": [
    "Consider two tasks:\n",
    "\n",
    "T1: Is this image a picture of Mitchell?\n",
    "\n",
    "T2: What's the facial expression in the picture?\n",
    "\n",
    "Your Goal: to report how your network performs at tasks T1 and T2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b657577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0.post100\n"
     ]
    }
   ],
   "source": [
    "# GB: Packages:\n",
    "# GB: From previous file:\n",
    "import torch # GB: Contains torch.utils.data?\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# GB: Added:\n",
    "import cv2 # For img_loader.\n",
    "import numpy as np\n",
    "from torchvision.datasets import ImageFolder # GB: For Helper Function.\n",
    "# GB: Ref.: https://pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html\n",
    "# GB: Ref.: https://discuss.pytorch.org/t/how-to-load-images-from-different-folders-in-the-same-batch/18942/6\n",
    "print(torch.__version__) # GB: Added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1afc474d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.folder.ImageFolder'>\n",
      "['an2i', 'at33', 'boland', 'bpm', 'ch4f', 'cheyer', 'choon', 'danieln', 'glickman', 'karyadi', 'kawamura', 'kk49', 'megak', 'mitchell', 'night', 'phoebe', 'saavik', 'steffi', 'sz24', 'tammo']\n",
      "('an2i', 'at33', 'boland', 'bpm', 'ch4f', 'cheyer', 'choon', 'danieln', 'glickman', 'karyadi', 'kawamura', 'kk49', 'megak', 'mitchell', 'night', 'phoebe', 'saavik', 'steffi', 'sz24', 'tammo')\n"
     ]
    }
   ],
   "source": [
    "# GB: Helper Functions:\n",
    "def img_loader(filename):\n",
    "    return cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "def img_folder():\n",
    "    root = './faces/' # GB: Put in here to not get lost.\n",
    "    # GB: Changed from 3D to 1D, i.e. from (0.5, 0.5, 0.5) to (0.5,). NB The trailing comma might be important.\n",
    "    # GB: Parameters: means and standard deviations.\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "    return ImageFolder(root=root, loader=img_loader, transform=transform)\n",
    "\n",
    "dataset = img_folder()\n",
    "trainset = img_folder()\n",
    "testset = img_folder()\n",
    "dummyset = img_folder()\n",
    "trainset_2 = img_folder()\n",
    "testset_2 = img_folder()\n",
    "data = img_folder() # GB: ImageFolder(root=root, loader=img_loader, transform=transform)\n",
    "print(type(data))\n",
    "print(data.classes)\n",
    "\n",
    "# GB: Moved: trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True) # GB: , num_workers=2\n",
    "# GB: Moved: trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True) # GB: , num_workers=2\n",
    "\n",
    "# GB: Sequence? It's just a tuple:\n",
    "# GB: classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "# GB: Alt for faces.userid [1]:\n",
    "# GB: <userid> is the user id of the person in the image, and this field has 20 values:\n",
    "classes_1 = ('an2i', 'at33', 'boland', 'bpm', 'ch4f', 'cheyer', 'choon', 'danieln', 'glickman', 'karyadi', 'kawamura', 'kk49', 'megak', 'mitchell', 'night', 'phoebe', 'saavik', 'steffi', 'sz24', 'tammo')\n",
    "classes_2 = ('angry', 'happy', 'neutral', 'sad')\n",
    "classes_3 = ('mitchell', 'not_mitchell')\n",
    "print(classes_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45833888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<str> <int> <folder_1> <folder_2> <userid> <pose> <expression> <eyes> <scale>\n",
      "[['./faces/an2i/an2i_left_angry_open.pgm' '0' 'faces' 'an2i' 'an2i'\n",
      "  'left' 'angry' 'open' '1']\n",
      " ['./faces/an2i/an2i_left_angry_open_2.pgm' '0' 'faces' 'an2i' 'an2i'\n",
      "  'left' 'angry' 'open' '2']\n",
      " ['./faces/an2i/an2i_left_angry_open_4.pgm' '0' 'faces' 'an2i' 'an2i'\n",
      "  'left' 'angry' 'open' '4']\n",
      " ['./faces/an2i/an2i_left_angry_sunglasses.pgm' '0' 'faces' 'an2i' 'an2i'\n",
      "  'left' 'angry' 'sunglasses' '1']\n",
      " ['./faces/an2i/an2i_left_angry_sunglasses_2.pgm' '0' 'faces' 'an2i'\n",
      "  'an2i' 'left' 'angry' 'sunglasses' '2']]\n",
      "['angry', 'happy', 'neutral', 'sad']\n",
      "<str> <int> <folder_1> <folder_2> <userid> <pose> <expression> <eyes> <scale> <dummy>\n",
      "[['./faces/an2i/an2i_left_angry_open.pgm' '0' 'faces' 'an2i' 'an2i'\n",
      "  'left' 'angry' 'open' '1' '0']\n",
      " ['./faces/an2i/an2i_left_angry_open_2.pgm' '0' 'faces' 'an2i' 'an2i'\n",
      "  'left' 'angry' 'open' '2' '0']\n",
      " ['./faces/an2i/an2i_left_angry_open_4.pgm' '0' 'faces' 'an2i' 'an2i'\n",
      "  'left' 'angry' 'open' '4' '0']\n",
      " ['./faces/an2i/an2i_left_angry_sunglasses.pgm' '0' 'faces' 'an2i' 'an2i'\n",
      "  'left' 'angry' 'sunglasses' '1' '0']\n",
      " ['./faces/an2i/an2i_left_angry_sunglasses_2.pgm' '0' 'faces' 'an2i'\n",
      "  'an2i' 'left' 'angry' 'sunglasses' '2' '0']]\n"
     ]
    }
   ],
   "source": [
    "# GB: Data Pump:\n",
    "# GB: <class 'torchvision.datasets.folder.ImageFolder'>\n",
    "# GB: From documentation: List[Tuple[str, int]].\n",
    "# GB: NB Can't use = torch.utils.data.Subset(dataset, indicies) because it drops .imgs and other attributes.\n",
    "# GB: = dataset.imgs # GB: List of tuples.\n",
    "# GB: Maybe revisit data types.\n",
    "# GB: Trying... .imgs:\n",
    "\n",
    "# GB: Could probably be done outside of NumPy as a list. # GB: Done.\n",
    "# GB: Assumes all are well formed: # GB: Check .bin images!!!\n",
    "# GB: Need to fix data types.\n",
    "fields = ([r[0]\n",
    "        .replace('_4.pgm', '_4') # GB: Care with order!\n",
    "        .replace('_2.pgm', '_2')\n",
    "        .replace('.pgm', '_1')\n",
    "        .replace('_', '/')\n",
    "        .replace('./', '') # GB: .\n",
    "        .split('/') for r in dataset.imgs]) # GB: Chained.\n",
    "\n",
    "arr = np.column_stack((dataset.imgs, fields))\n",
    "print('<str> <int> <folder_1> <folder_2> <userid> <pose> <expression> <eyes> <scale>')\n",
    "print(arr[:5])\n",
    "\n",
    "# GB: Split out as function?\n",
    "# GB: Pre-processor:\n",
    "# GB: <expression> is the facial expression of the person, and this field has 4 values: neutral, happy, sad, angry.\n",
    "f = 6 # GB: Defaults: 4 (userid), 6 (expression)\n",
    "fs = np.unique(arr[:, f])\n",
    "fs = fs.tolist()\n",
    "print(fs) # GB: ['angry' 'happy' 'neutral' 'sad']\n",
    "# GB: Double check classes for folder_2 are alphabetical.\n",
    "\n",
    "dummy = []\n",
    "for p in range(arr.shape[0]):\n",
    "    p_value = arr[p, f] # GB: Current value. GB: arr[][]?\n",
    "    p_class = fs.index(p_value) # GB: Index of current value in values.\n",
    "    # p_tmp = 0 if p_class == 13 else 1\n",
    "    tup_dummy = (dummyset.imgs[p][0], int(p_class))\n",
    "    dummyset.imgs[p] = tup_dummy\n",
    "    trainset_2.imgs[p] = tup_dummy # GB: Same.\n",
    "    testset_2.imgs[p] = tup_dummy # GB: Same.\n",
    "    dummy.append(int(p_class))\n",
    "\n",
    "# GB: Quick and dirty:\n",
    "arr = np.column_stack((arr, dummy))\n",
    "print('<str> <int> <folder_1> <folder_2> <userid> <pose> <expression> <eyes> <scale> <dummy>')\n",
    "print(arr[:5])\n",
    "\n",
    "# GB: Resolutions:\n",
    "# GB: Split out as function?\n",
    "filter_1 = ((arr[:, 8]=='1') ) # GB: 1 = full res. & (x[:, 5]!='up')\n",
    "filter_2 = ((arr[:, 8]=='2') ) # GB: 2 = half res\n",
    "filter_4 = ((arr[:, 8]=='4') ) # GB: 4 = quarter res.\n",
    "filter_not_1 = ((arr[:, 8]!='1') ) # GB: 1 = full res. | (x[:, 5]=='up')\n",
    "filter_not_2 = ((arr[:, 8]!='2') ) # GB: 2 = half res.\n",
    "filter_not_4 = ((arr[:, 8]!='4') ) # GB: 4 = quarter res.\n",
    "\n",
    "# GB: Parameter:\n",
    "filter_ = filter_1 # GB: Default: filter_4.\n",
    "filter_not_ = filter_not_1 # GB: Default: filter_not_4.\n",
    "\n",
    "arr_filtered = arr[filter_]\n",
    "arr_filtered_not = arr[filter_not_]\n",
    "\n",
    "# GB: ...\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_y_train, X_y_test = train_test_split(arr_filtered, test_size=0.33, random_state=42, shuffle=False)\n",
    "# GB: Default test_size: 0.33.\n",
    "\n",
    "# GB: Remove images that are not in required resolution.\n",
    "tuple_filtered_not = ('', -1)\n",
    "tuple_filtered_not_2 = ('', -1)\n",
    "for p in range(arr_filtered_not.shape[0]):\n",
    "    tuple_filtered_not = (arr_filtered_not[p][0], int(arr_filtered_not[p][1]))\n",
    "    dataset.imgs.remove(tuple_filtered_not)\n",
    "    trainset.imgs.remove(tuple_filtered_not)\n",
    "    testset.imgs.remove(tuple_filtered_not)\n",
    "    # GB: Repeat for dummy sets, don't really want two sets.\n",
    "    tuple_filtered_not_2 = (arr_filtered_not[p][0], int(arr_filtered_not[p][9]))\n",
    "    dummyset.imgs.remove(tuple_filtered_not_2)\n",
    "    trainset_2.imgs.remove(tuple_filtered_not_2)\n",
    "    testset_2.imgs.remove(tuple_filtered_not_2)\n",
    "\n",
    "# GB: Remove test to leave train.\n",
    "tuple_test = ('', -1)\n",
    "tuple_test_2 = ('', -1)\n",
    "for s in range(X_y_test.shape[0]):\n",
    "    tuple_test = (X_y_test[s][0], int(X_y_test[s][1]))\n",
    "    trainset.imgs.remove(tuple_test)\n",
    "    # GB: Repeat for dummy sets, don't really want two sets.\n",
    "    tuple_test_2 = (X_y_test[s][0], int(X_y_test[s][9]))\n",
    "    trainset_2.imgs.remove(tuple_test_2)\n",
    "\n",
    "# GB: Remove train to leave test.\n",
    "tuple_train = ('', -1)\n",
    "tuple_train_2 = ('', -1)\n",
    "for q in range(X_y_train.shape[0]):\n",
    "    tuple_train = (X_y_train[q][0], int(X_y_train[q][1]))\n",
    "    testset.imgs.remove(tuple_train)\n",
    "    # GB: Repeat for dummy sets, don't really want two sets.\n",
    "    tuple_train_2 = (X_y_train[q][0], int(X_y_train[q][9]))\n",
    "    testset_2.imgs.remove(tuple_train_2)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset_2, batch_size=4, shuffle=True, num_workers=0) # GB: Changed num_workers=2 to 0\n",
    "testloader = torch.utils.data.DataLoader(testset_2, batch_size=4, shuffle=True, num_workers=0) # GB: Changed num_workers=2 to 0\n",
    "# GB: dataset.imgs.remove((PATH, INDEX))\n",
    "# GB: Ref.: https://stackoverflow.com/questions/64914820/removing-sample-from-a-pytorch-dataset-object\n",
    "# GB: If a list is tried instead of a tuple: _\n",
    "# GB: ValueError: The truth value of an array with more than one element is ambiguous.\n",
    "# GB: If genuinely not in .imgs: ValueError: list.remove(x): x not in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e76cd970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GavNet: total params: 1518260\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=12528, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# GB: \"... use the LeNet-5 architecture\". Classic or modified?\n",
    "# GB: Assume modified, what to do about pooling 3x2 or 2x2?\n",
    "# GB: [1] \"<scale> is the scale of the image, and this field has 3 values: 1, 2, and 4.\", oh no it doesn't!\n",
    "# GB: null, _2 or _4.\n",
    "# GB: Finding 'mitchell' (13, unlucky for some)...\n",
    "# GB: <expression>...\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn # GB: Used in previous.\n",
    "import torch.nn.functional as F # GB: Used in previous.\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms # GB: Above.\n",
    "\n",
    "# GB: Parameters:\n",
    "dim_1 = 29 * 27\n",
    "dim_2 = 13 * 12\n",
    "dim_4 = 5 * 4\n",
    "dim_ = dim_1 # GB: Default: dim_4.\n",
    "\n",
    "c_1 = 20\n",
    "c_2 = 4\n",
    "c_3 = 2\n",
    "c_ = c_2 # GB: Default: ?\n",
    "\n",
    "# GB: Forked in start.\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super(Net, self).__init__()\n",
    "        if name:\n",
    "            self.name = name\n",
    "        # GB: Ref.: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(5, 5))\n",
    "        # GB: Taken literally, so changed from 3 to 1.\n",
    "        # GB: ..., which produces ten outputs. Hence, changed from 6 to out_channels=10. Try back to 6...\n",
    "        # GB: Changed from 5 to kernel_size=(5, 5). Reads as if it necessitate ten outputs, it doesn't necessitate.\n",
    "        # GB: NB height x width, so assumed 5x5 is height x width, i.e. the same order.\n",
    "        # GB: Ref.: https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)) # GB: h x w. # GB: Changed from 3x2 to 2x2. \n",
    "        # GB: Changed from 2 to kernel_size=(3, 2).\n",
    "        # GB: NB Height x width, so assumed 3x2 is height x width, i.e. in the same order provided.\n",
    "        # GB: Step size? Stride changed from 2 to stride=(2, 2), for clarity.\n",
    "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=16, kernel_size=5)\n",
    "        # GB: Changed from 6 to in_channels=10. Try back to 6...\n",
    "        # GB: switched remaining parameters from positional arguments to keyword arguments.\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)) # GB: Added for clarity.# GB: Changed from 3x2 to 2x2.\n",
    "        # GB: .1 Change the Net.forward method to be able to accept a 28x28 image rather than a 32x32 input.\n",
    "        self.fc1 = nn.Linear(dim_ * 16, 120) # GB: Changed from 5 * 5 to 8 * 6 to 4 * 3.\n",
    "        # GB: Try 5 x 4 x 16 for 32 x 30 _4.\n",
    "        # GB: in_features (int) – size of each input sample = w x h x c.\n",
    "        # GB: out_features (int) – size of each output sample = 120.\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, c_) # GB: Greater than 10 outputs? Trying exactly 20... ok-ish.\n",
    "        # GB: Only place to change outputs, apart from metrics at the end.\n",
    "        \n",
    "        # compute the total number of parameters\n",
    "        total_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        print(self.name + ': total params:', total_params)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # GB: .2 Change the Net.forward method to be able to accept a 28x28 image rather than a 32x32 input.\n",
    "        # GB: RuntimeError: shape '[-1, 400]' is invalid for input of size 768\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x))) # GB: Added for clarity.\n",
    "        # GB: print('x.shape:', x.shape) # GB: Useful check.\n",
    "        x = x.view(-1, dim_ * 16) # GB: Changed from 5 * 5 to 8 * 6 to 3 * 4, keeping to w x h x c.\n",
    "        # GB: Try 5 x 4 x 16 for 32 x 30 _4.\n",
    "        # GB: x = x.view(x.size(0), -1) # GB: Useful check.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net(name='GavNet') # GB: Keep in main and pass to train/test functions?\n",
    "print(net) # GB: Added.\n",
    "# GB: Forked in end.\n",
    "\n",
    "def train(data_dir, *args, **kwargs): # GB: [1].\n",
    "# feel free to modify the parameters as appropriate\n",
    "    # GB: Okay:\n",
    "    lr, e, m = data_dir['lr'], data_dir['e'], data_dir['m']\n",
    "    ##########\n",
    "    # GB: Forked in:\n",
    "    import torch.optim as optim # GB: To move to top.\n",
    "\n",
    "    # GB: Added:\n",
    "    learning_rate = lr #0.002 # GB: Changed from 0.001.\n",
    "    momentum = m\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=m) # GB: Changed.\n",
    "    # GB: Ref.: https://pytorch.org/docs/stable/generated/torch.optim.SGD.html\n",
    "    ##########\n",
    "    ##########\n",
    "    # GB: Forked in:\n",
    "    import time # GB: To move to top.\n",
    "\n",
    "    start = time.time()\n",
    "    epochs = e # int(round(e)) #2 # GB: Changed from default of 2.\n",
    "    resolution = 960 # GB: Added. \n",
    "    #an2i_left_angry_open.pgm: indicate a full-resolution image (128 columns by 120 rows); = 15360\n",
    "    #an2i_left_angry_open_2.pgm: indicates a half-resolution image (64 by 60) and = 3840\n",
    "    #an2i_left_angry_open_4.pgm: indicates a quarter-resolution image (32 by 30). = 960\n",
    "\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0): # GB: To change from trainloader to data.\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # GB: if inputs.numpy().size != resolution: # GB: Added.\n",
    "            # GB:   break # GB: Add back in later, if needed.\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics # GB: Adjust for expected data.\n",
    "            running_loss += loss.item()\n",
    "            if i % 20 == 19:    # print every 2000 mini-batches # GB: Needs tweeked for dataset. # GB: Chnaged from 2000, 1999\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 20)) # GB: Chnaged from 20.\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    end = time.time()\n",
    "    print('training time ', end-start)\n",
    "    # GB: Takes approximately ... minutes to complete learning_rate = 0.001.\n",
    "    ##########\n",
    "\n",
    "    # GB: pass # GB: Original End.\n",
    "\n",
    "def test(data_dir, *args, **kwargs): # GB: [1].\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        tmp = 0\n",
    "        for data in testloader:\n",
    "            tmp += 1 \n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('runs of batches', tmp)\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "    print('c', correct)\n",
    "    # GB: Are there 10,000? No, needs corrected.\n",
    "    #pass\n",
    "    return round(1 - (correct / total), 6)\n",
    "\n",
    "def main():\n",
    "# Training settings\n",
    "    # GB: CLI, i.e. not Jupyter? Too much in one exercise.\n",
    "    # GB: parser.add_argument('--data', type=str, default='./faces', metavar='N'\n",
    "    # GB:                     , help='Path to directory containing faces dataset.')\n",
    "    # GB: args = parser.parse_args()\n",
    "    # GB: data_dir = args.data\n",
    "    # GB: train(data_dir + '/train') # GB: I didn't take this approach to split data, it should have been in the instructions. \n",
    "    # GB: test(data_dir + '/test') # GB: I didn't take this approach to split data, it should have been in the instructions.\n",
    "    # GB: Put net high enough to be called by all functions?\n",
    "    data_dir = 'dummy'\n",
    "    # GB: train(data_dir) # GB: Toggle train.\n",
    "    test(data_dir)\n",
    "    path = './models/pytorch-model-2024-05-13.tar' # GB: Changed from .pth to .tar.\n",
    "    epoch = 10\n",
    "    # print(net.state_dict())\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            # 'optimizer_state_dict': optimizer.state_dict(),\n",
    "            # 'loss': loss#,\n",
    "            #...\n",
    "            }, path) # GB: Changed from PATH.\n",
    "    # GB: Needs fully refactored to get other variables.\n",
    "    '''\n",
    "    # GB: Load:\n",
    "    model = TheModelClass(*args, **kwargs)\n",
    "    optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "\n",
    "    checkpoint = torch.load(PATH)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "\n",
    "    model.eval()\n",
    "    # - or -\n",
    "    model.train()\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #main()\n",
    "    pass\n",
    "# GB: Stopped here. I've spent days on this exercise trying to understand what the requirements are.\n",
    "# GB: Raised a ticket, which only confirmed that the instructions are unclear.\n",
    "# GB: The code above runs a successful model and saves it. I can import in any resolution and move between _\n",
    "# GB: userid, pose, etc. With more time I could improve performance and accuracy and refactor a more advanced _\n",
    "# GB: save load operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bbe0348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 1.384\n",
      "[1,    40] loss: 1.385\n",
      "[1,    60] loss: 1.399\n",
      "[1,    80] loss: 1.397\n",
      "[1,   100] loss: 1.389\n",
      "[2,    20] loss: 1.387\n",
      "[2,    40] loss: 1.390\n",
      "[2,    60] loss: 1.378\n",
      "[2,    80] loss: 1.388\n",
      "[2,   100] loss: 1.404\n",
      "Finished Training\n",
      "training time  4.0883469581604\n",
      "runs of batches 52\n",
      "Accuracy of the network on the 10000 test images: 25 %\n",
      "52\n",
      "[1,    20] loss: 1.383\n",
      "[1,    40] loss: 1.390\n",
      "[1,    60] loss: 1.388\n",
      "[1,    80] loss: 1.394\n",
      "[1,   100] loss: 1.388\n",
      "[2,    20] loss: 1.386\n",
      "[2,    40] loss: 1.387\n",
      "[2,    60] loss: 1.390\n",
      "[2,    80] loss: 1.389\n",
      "[2,   100] loss: 1.390\n",
      "Finished Training\n",
      "training time  2.8686962127685547\n",
      "runs of batches 52\n",
      "Accuracy of the network on the 10000 test images: 25 %\n",
      "53\n",
      "[1,    20] loss: 1.385\n",
      "[1,    40] loss: 1.386\n",
      "[1,    60] loss: 1.391\n",
      "[1,    80] loss: 1.386\n",
      "[1,   100] loss: 1.389\n",
      "[2,    20] loss: 1.384\n",
      "[2,    40] loss: 1.382\n",
      "[2,    60] loss: 1.386\n",
      "[2,    80] loss: 1.394\n",
      "[2,   100] loss: 1.389\n",
      "Finished Training\n",
      "training time  3.217306137084961\n",
      "runs of batches 52\n",
      "Accuracy of the network on the 10000 test images: 26 %\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "def run_model(learning_rate):\n",
    "    data_dir = 'dummy'\n",
    "    train(data_dir)\n",
    "    test_result = test(data_dir)\n",
    "    return test_result\n",
    "\n",
    "# Python3 code to iterate over a list\n",
    "list = [0.01, 0.05, 0.1]\n",
    "\n",
    "# Using for loop\n",
    "for i in list:\n",
    "    best = run_model(list)\n",
    "    print(best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88f041aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 1.089                                                          \n",
      "[1,    40] loss: 1.152                                                          \n",
      "[1,    60] loss: 1.164                                                          \n",
      "[1,    80] loss: 1.211                                                          \n",
      "[1,   100] loss: 1.255                                                          \n",
      "[2,    20] loss: 1.046                                                          \n",
      "[2,    40] loss: 1.383                                                          \n",
      "[2,    60] loss: 1.169                                                          \n",
      "[2,    80] loss: 1.235                                                          \n",
      "[2,   100] loss: 1.180                                                          \n",
      "Finished Training                                                               \n",
      "training time                                                                   \n",
      "3.6575348377227783                                                              \n",
      "runs of batches                                                                 \n",
      "52                                                                              \n",
      "Accuracy of the network on the 10000 test images: 31 %                          \n",
      "c                                                                               \n",
      "65                                                                              \n",
      "[1,    20] loss: 1.050                                                          \n",
      "[1,    40] loss: 1.319                                                          \n",
      "[1,    60] loss: 1.285                                                          \n",
      "[1,    80] loss: 1.327                                                          \n",
      "[1,   100] loss: 1.221                                                          \n",
      "[2,    20] loss: 1.023                                                          \n",
      "[2,    40] loss: 1.211                                                          \n",
      "[2,    60] loss: 1.273                                                          \n",
      "[2,    80] loss: 1.269                                                          \n",
      "[2,   100] loss: 1.452                                                          \n",
      "[3,    20] loss: 1.344                                                          \n",
      "[3,    40] loss: 1.222                                                          \n",
      "[3,    60] loss: 1.166                                                          \n",
      "[3,    80] loss: 1.417                                                          \n",
      "[3,   100] loss: 1.365                                                          \n",
      "[4,    20] loss: 1.220                                                          \n",
      "[4,    40] loss: 1.206                                                          \n",
      "[4,    60] loss: 1.305                                                          \n",
      "[4,    80] loss: 1.248                                                          \n",
      "[4,   100] loss: 1.198                                                          \n",
      "[5,    20] loss: 1.153                                                          \n",
      "[5,    40] loss: 1.192                                                          \n",
      "[5,    60] loss: 1.155                                                          \n",
      "[5,    80] loss: 1.120                                                          \n",
      "[5,   100] loss: 1.150                                                          \n",
      "Finished Training                                                               \n",
      "training time                                                                   \n",
      "7.5164690017700195                                                              \n",
      "runs of batches                                                                 \n",
      "52                                                                              \n",
      "Accuracy of the network on the 10000 test images: 26 %                          \n",
      "c                                                                               \n",
      "54                                                                              \n",
      "[1,    20] loss: 1.891                                                          \n",
      "[1,    40] loss: 1.414                                                          \n",
      "[1,    60] loss: 1.468                                                          \n",
      "[1,    80] loss: 1.397                                                          \n",
      "[1,   100] loss: 1.414                                                          \n",
      "Finished Training                                                               \n",
      "training time                                                                   \n",
      "1.8762099742889404                                                              \n",
      "runs of batches                                                                 \n",
      "52                                                                              \n",
      "Accuracy of the network on the 10000 test images: 24 %                          \n",
      "c                                                                               \n",
      "50                                                                              \n",
      "[1,    20] loss: 1.403                                                          \n",
      "[1,    40] loss: 1.385                                                          \n",
      "[1,    60] loss: 1.402                                                          \n",
      "[1,    80] loss: 1.390                                                          \n",
      "[1,   100] loss: 1.397                                                          \n",
      "[2,    20] loss: 1.381                                                          \n",
      "[2,    40] loss: 1.387                                                          \n",
      "[2,    60] loss: 1.398                                                          \n",
      "[2,    80] loss: 1.387                                                          \n",
      "[2,   100] loss: 1.398                                                          \n",
      "[3,    20] loss: 1.373                                                          \n",
      "[3,    40] loss: 1.409                                                          \n",
      "[3,    60] loss: 1.391                                                          \n",
      "[3,    80] loss: 1.397                                                          \n",
      "[3,   100] loss: 1.394                                                          \n",
      "[4,    20] loss: 1.384                                                          \n",
      "[4,    40] loss: 1.403                                                          \n",
      "[4,    60] loss: 1.386                                                          \n",
      "[4,    80] loss: 1.401                                                          \n",
      "[4,   100] loss: 1.390                                                          \n",
      "[5,    20] loss: 1.390                                                          \n",
      "[5,    40] loss: 1.401                                                          \n",
      "[5,    60] loss: 1.390                                                          \n",
      "[5,    80] loss: 1.393                                                          \n",
      "[5,   100] loss: 1.400                                                          \n",
      "[6,    20] loss: 1.374                                                          \n",
      "[6,    40] loss: 1.403                                                          \n",
      "[6,    60] loss: 1.401                                                          \n",
      "[6,    80] loss: 1.384                                                          \n",
      "[6,   100] loss: 1.403                                                          \n",
      "[7,    20] loss: 1.391                                                          \n",
      "[7,    40] loss: 1.395                                                          \n",
      "[7,    60] loss: 1.393                                                          \n",
      "[7,    80] loss: 1.395                                                          \n",
      "[7,   100] loss: 1.392                                                          \n",
      "[8,    20] loss: 1.392                                                          \n",
      "[8,    40] loss: 1.393                                                          \n",
      "[8,    60] loss: 1.383                                                          \n",
      "[8,    80] loss: 1.402                                                          \n",
      "[8,   100] loss: 1.395                                                          \n",
      "Finished Training                                                               \n",
      "training time                                                                   \n",
      "13.272900104522705                                                              \n",
      "runs of batches                                                                 \n",
      "52                                                                              \n",
      "Accuracy of the network on the 10000 test images: 24 %                          \n",
      "c                                                                               \n",
      "50                                                                              \n",
      "[1,    20] loss: 1.393                                                          \n",
      "[1,    40] loss: 1.393                                                          \n",
      "[1,    60] loss: 1.393                                                          \n",
      "[1,    80] loss: 1.395                                                          \n",
      "[1,   100] loss: 1.393                                                          \n",
      "[2,    20] loss: 1.388                                                          \n",
      "[2,    40] loss: 1.391                                                          \n",
      "[2,    60] loss: 1.395                                                          \n",
      "[2,    80] loss: 1.398                                                          \n",
      "[2,   100] loss: 1.393                                                          \n",
      "[3,    20] loss: 1.386                                                          \n",
      "[3,    40] loss: 1.395                                                          \n",
      "[3,    60] loss: 1.385                                                          \n",
      "[3,    80] loss: 1.396                                                          \n",
      "[3,   100] loss: 1.392                                                          \n",
      "[4,    20] loss: 1.384                                                          \n",
      "[4,    40] loss: 1.400                                                          \n",
      "[4,    60] loss: 1.389                                                          \n",
      "[4,    80] loss: 1.398                                                          \n",
      "[4,   100] loss: 1.395                                                          \n",
      "[5,    20] loss: 1.396                                                          \n",
      "[5,    40] loss: 1.391                                                          \n",
      "[5,    60] loss: 1.386                                                          \n",
      "[5,    80] loss: 1.400                                                          \n",
      "[5,   100] loss: 1.394                                                          \n",
      "[6,    20] loss: 1.390                                                          \n",
      "[6,    40] loss: 1.391                                                          \n",
      "[6,    60] loss: 1.391                                                          \n",
      "[6,    80] loss: 1.396                                                          \n",
      "[6,   100] loss: 1.393                                                          \n",
      "[7,    20] loss: 1.390                                                          \n",
      "[7,    40] loss: 1.399                                                          \n",
      "[7,    60] loss: 1.393                                                          \n",
      "[7,    80] loss: 1.397                                                          \n",
      "[7,   100] loss: 1.394                                                          \n",
      "Finished Training                                                               \n",
      "training time                                                                   \n",
      "11.156193971633911                                                              \n",
      "runs of batches                                                                 \n",
      "52                                                                              \n",
      "Accuracy of the network on the 10000 test images: 25 %                          \n",
      "c                                                                               \n",
      "52                                                                              \n",
      "[1,    20] loss: 1.380                                                          \n",
      "[1,    40] loss: 1.395                                                          \n",
      "[1,    60] loss: 1.391                                                          \n",
      "[1,    80] loss: 1.388                                                          \n",
      "[1,   100] loss: 1.389                                                          \n",
      "[2,    20] loss: 1.384                                                          \n",
      "[2,    40] loss: 1.384                                                          \n",
      "[2,    60] loss: 1.396                                                          \n",
      "[2,    80] loss: 1.390                                                          \n",
      "[2,   100] loss: 1.391                                                          \n",
      "[3,    20] loss: 1.388                                                          \n",
      "[3,    40] loss: 1.391                                                          \n",
      "[3,    60] loss: 1.389                                                          \n",
      "[3,    80] loss: 1.388                                                          \n",
      "[3,   100] loss: 1.390                                                          \n",
      "[4,    20] loss: 1.388                                                          \n",
      "[4,    40] loss: 1.389                                                          \n",
      "[4,    60] loss: 1.392                                                          \n",
      "[4,    80] loss: 1.387                                                          \n",
      "[4,   100] loss: 1.390                                                          \n",
      "[5,    20] loss: 1.388                                                          \n",
      "[5,    40] loss: 1.387                                                          \n",
      "[5,    60] loss: 1.391                                                          \n",
      "[5,    80] loss: 1.390                                                          \n",
      "[5,   100] loss: 1.388                                                          \n",
      "[6,    20] loss: 1.389                                                          \n",
      "[6,    40] loss: 1.390                                                          \n",
      "[6,    60] loss: 1.384                                                          \n",
      "[6,    80] loss: 1.394                                                          \n",
      "[6,   100] loss: 1.389                                                          \n",
      "[7,    20] loss: 1.390                                                          \n",
      "[7,    40] loss: 1.390                                                          \n",
      "[7,    60] loss: 1.390                                                          \n",
      "[7,    80] loss: 1.389                                                          \n",
      "[7,   100] loss: 1.389                                                          \n",
      "[8,    20] loss: 1.390                                                          \n",
      "[8,    40] loss: 1.389                                                          \n",
      "[8,    60] loss: 1.389                                                          \n",
      "[8,    80] loss: 1.389                                                          \n",
      "[8,   100] loss: 1.389                                                          \n",
      "Finished Training                                                               \n",
      "training time                                                                   \n",
      "12.751268863677979                                                              \n",
      "runs of batches                                                                 \n",
      "52                                                                              \n",
      "Accuracy of the network on the 10000 test images: 25 %                          \n",
      "c                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52                                                                              \n",
      "[1,    20] loss: 1.386                                                          \n",
      "[1,    40] loss: 1.390                                                          \n",
      "[1,    60] loss: 1.385                                                          \n",
      "[1,    80] loss: 1.394                                                          \n",
      "[1,   100] loss: 1.389                                                          \n",
      "[2,    20] loss: 1.381                                                          \n",
      "[2,    40] loss: 1.382                                                          \n",
      "[2,    60] loss: 1.385                                                          \n",
      "[2,    80] loss: 1.394                                                          \n",
      "[2,   100] loss: 1.396                                                          \n",
      "[3,    20] loss: 1.387                                                          \n",
      "[3,    40] loss: 1.387                                                          \n",
      "[3,    60] loss: 1.391                                                          \n",
      "[3,    80] loss: 1.391                                                          \n",
      "[3,   100] loss: 1.389                                                          \n",
      "[4,    20] loss: 1.375                                                          \n",
      "[4,    40] loss: 1.391                                                          \n",
      "[4,    60] loss: 1.390                                                          \n",
      "[4,    80] loss: 1.395                                                          \n",
      "[4,   100] loss: 1.388                                                          \n",
      "[5,    20] loss: 1.384                                                          \n",
      "[5,    40] loss: 1.387                                                          \n",
      "[5,    60] loss: 1.389                                                          \n",
      "[5,    80] loss: 1.390                                                          \n",
      "[5,   100] loss: 1.389                                                          \n",
      "[6,    20] loss: 1.386                                                          \n",
      "[6,    40] loss: 1.388                                                          \n",
      "[6,    60] loss: 1.390                                                          \n",
      "[6,    80] loss: 1.388                                                          \n",
      "[6,   100] loss: 1.388                                                          \n",
      "Finished Training                                                               \n",
      "training time                                                                   \n",
      "9.656260013580322                                                               \n",
      "runs of batches                                                                 \n",
      "52                                                                              \n",
      "Accuracy of the network on the 10000 test images: 25 %                          \n",
      "c                                                                               \n",
      "52                                                                              \n",
      "[1,    20] loss: 1.398                                                          \n",
      "[1,    40] loss: 1.393                                                          \n",
      "[1,    60] loss: 1.376                                                          \n",
      "[1,    80] loss: 1.414                                                          \n",
      "[1,   100] loss: 1.396                                                          \n",
      "[2,    20] loss: 1.399                                                          \n",
      "[2,    40] loss: 1.392                                                          \n",
      "[2,    60] loss: 1.400                                                          \n",
      "[2,    80] loss: 1.402                                                          \n",
      "[2,   100] loss: 1.398                                                          \n",
      "[3,    20] loss: 1.370                                                          \n",
      "[3,    40] loss: 1.417                                                          \n",
      "[3,    60] loss: 1.395                                                          \n",
      "[3,    80] loss: 1.404                                                          \n",
      "[3,   100] loss: 1.386                                                          \n",
      "[4,    20] loss: 1.401                                                          \n",
      "[4,    40] loss: 1.396                                                          \n",
      "[4,    60] loss: 1.394                                                          \n",
      "[4,    80] loss: 1.395                                                          \n",
      "[4,   100] loss: 1.395                                                          \n",
      "[5,    20] loss: 1.385                                                          \n",
      "[5,    40] loss: 1.394                                                          \n",
      "[5,    60] loss: 1.404                                                          \n",
      "[5,    80] loss: 1.391                                                          \n",
      "[5,   100] loss: 1.404                                                          \n",
      "[6,    20] loss: 1.394                                                          \n",
      "[6,    40] loss: 1.395                                                          \n",
      "[6,    60] loss: 1.397                                                          \n",
      "[6,    80] loss: 1.404                                                          \n",
      "[6,   100] loss: 1.399                                                          \n",
      "Finished Training                                                               \n",
      "training time                                                                   \n",
      "9.766052007675171                                                               \n",
      "runs of batches                                                                 \n",
      "52                                                                              \n",
      "Accuracy of the network on the 10000 test images: 25 %                          \n",
      "c                                                                               \n",
      "52                                                                              \n",
      "[1,    20] loss: 1.389                                                          \n",
      "[1,    40] loss: 1.393                                                          \n",
      "[1,    60] loss: 1.389                                                          \n",
      "[1,    80] loss: 1.387                                                          \n",
      "[1,   100] loss: 1.388                                                          \n",
      "[2,    20] loss: 1.385                                                          \n",
      "[2,    40] loss: 1.384                                                          \n",
      "[2,    60] loss: 1.394                                                          \n",
      "[2,    80] loss: 1.389                                                          \n",
      "[2,   100] loss: 1.389                                                          \n",
      "[3,    20] loss: 1.388                                                          \n",
      "[3,    40] loss: 1.381                                                          \n",
      "[3,    60] loss: 1.394                                                          \n",
      "[3,    80] loss: 1.389                                                          \n",
      "[3,   100] loss: 1.391                                                          \n",
      "[4,    20] loss: 1.389                                                          \n",
      "[4,    40] loss: 1.391                                                          \n",
      "[4,    60] loss: 1.387                                                          \n",
      "[4,    80] loss: 1.390                                                          \n",
      "[4,   100] loss: 1.390                                                          \n",
      "[5,    20] loss: 1.379                                                          \n",
      "[5,    40] loss: 1.384                                                          \n",
      "[5,    60] loss: 1.401                                                          \n",
      "[5,    80] loss: 1.389                                                          \n",
      "[5,   100] loss: 1.389                                                          \n",
      "[6,    20] loss: 1.383                                                          \n",
      "[6,    40] loss: 1.390                                                          \n",
      "[6,    60] loss: 1.381                                                          \n",
      "[6,    80] loss: 1.401                                                          \n",
      "[6,   100] loss: 1.390                                                          \n",
      "[7,    20] loss: 1.384                                                          \n",
      "[7,    40] loss: 1.393                                                          \n",
      "[7,    60] loss: 1.386                                                          \n",
      "[7,    80] loss: 1.379                                                          \n",
      "[7,   100] loss: 1.402                                                          \n",
      "[8,    20] loss: 1.388                                                          \n",
      "[8,    40] loss: 1.386                                                          \n",
      "[8,    60] loss: 1.388                                                          \n",
      "[8,    80] loss: 1.392                                                          \n",
      "[8,   100] loss: 1.390                                                          \n",
      "[9,    20] loss: 1.388                                                          \n",
      "[9,    40] loss: 1.388                                                          \n",
      "[9,    60] loss: 1.389                                                          \n",
      "[9,    80] loss: 1.390                                                          \n",
      "[9,   100] loss: 1.393                                                          \n",
      "Finished Training                                                               \n",
      "training time                                                                   \n",
      "15.224069833755493                                                              \n",
      "runs of batches                                                                 \n",
      "52                                                                              \n",
      "Accuracy of the network on the 10000 test images: 25 %                          \n",
      "c                                                                               \n",
      "52                                                                              \n",
      "[1,    20] loss: 1.401                                                          \n",
      "[1,    40] loss: 1.386                                                          \n",
      "[1,    60] loss: 1.384                                                          \n",
      "[1,    80] loss: 1.407                                                          \n",
      "[1,   100] loss: 1.395                                                          \n",
      "[2,    20] loss: 1.404                                                          \n",
      "[2,    40] loss: 1.387                                                          \n",
      "[2,    60] loss: 1.414                                                          \n",
      "[2,    80] loss: 1.402                                                          \n",
      "[2,   100] loss: 1.416                                                          \n",
      "[3,    20] loss: 1.395                                                          \n",
      "[3,    40] loss: 1.408                                                          \n",
      "[3,    60] loss: 1.392                                                          \n",
      "[3,    80] loss: 1.401                                                          \n",
      "[3,   100] loss: 1.410                                                          \n",
      "[4,    20] loss: 1.394                                                          \n",
      "[4,    40] loss: 1.415                                                          \n",
      "[4,    60] loss: 1.410                                                          \n",
      "[4,    80] loss: 1.399                                                          \n",
      "[4,   100] loss: 1.399                                                          \n",
      "[5,    20] loss: 1.401                                                          \n",
      "[5,    40] loss: 1.397                                                          \n",
      "[5,    60] loss: 1.394                                                          \n",
      "[5,    80] loss: 1.399                                                          \n",
      "[5,   100] loss: 1.392                                                          \n",
      "[6,    20] loss: 1.407                                                          \n",
      "[6,    40] loss: 1.387                                                          \n",
      "[6,    60] loss: 1.427                                                          \n",
      "[6,    80] loss: 1.408                                                          \n",
      "[6,   100] loss: 1.414                                                          \n",
      "[7,    20] loss: 1.401                                                          \n",
      "[7,    40] loss: 1.407                                                          \n",
      "[7,    60] loss: 1.401                                                          \n",
      "[7,    80] loss: 1.407                                                          \n",
      "[7,   100] loss: 1.394                                                          \n",
      "Finished Training                                                               \n",
      "training time                                                                   \n",
      "11.515795946121216                                                              \n",
      "runs of batches                                                                 \n",
      "52                                                                              \n",
      "Accuracy of the network on the 10000 test images: 25 %                          \n",
      "c                                                                               \n",
      "53                                                                              \n",
      "100%|███████████████████| 10/10 [01:40<00:00, 10.00s/trial, best loss: 0.684466]\n",
      "{'e': 2.0, 'lr1': 0.031001069725507056, 'm': 0.6039457584198283}\n"
     ]
    }
   ],
   "source": [
    "# GB: At this point it had finished running. Make replacement for main(())\n",
    "# GB: Inspired by [2]\n",
    "# GB: https://github.com/hyperopt/hyperopt/wiki/FMin\n",
    "# GB: https://github.com/hyperopt/hyperopt/wiki/FMin#11-the-simplest-case\n",
    "# GB: Better ref than previous line\n",
    "# GB: https://hyperopt.github.io/hyperopt/tutorials/02.MultipleParameterTutorial/\n",
    "\n",
    "# GB: Trying... $ conda install intel::hyperopt # GB: Failed.\n",
    "# GB: Trying... $ pip install hyperopt # GB: Passed with errors.\n",
    "# GB: Come back to.\n",
    "\n",
    "#from hyperopt import hp, tpe, fmin\n",
    "\n",
    "#def run_model(learning_rate):\n",
    "    # GB: train(data_dir) # GB: Toggle train.\n",
    "#    test(data_dir)\n",
    "#    return loss\n",
    "\n",
    "# Single line bayesian optimization of polynomial function\n",
    "#best = fmin(fn=lambda x: run_model(x),\n",
    "#            space=hp.normal('x', 0.00001, 0.9),\n",
    "#            algo=tpe.suggest, \n",
    "#            max_evals=2000)\n",
    "\n",
    "from hyperopt import fmin, hp, tpe # GB: In alphabetical order.\n",
    "\n",
    "def run_model(params):\n",
    "    train(params)\n",
    "    test_result = test(params)\n",
    "    return test_result\n",
    "\n",
    "def objective(params): # GB: Test function.\n",
    "    # GB: print(params)\n",
    "    lr, e = params['lr'], params['e']\n",
    "    return np.sin(np.sqrt(lr**2 + e**2))\n",
    "\n",
    "space = {\n",
    "    'lr': hp.uniform('lr1', 0.001, 0.1), # GB: Default (pytorch): 0.001-.\n",
    "    'e': hp.uniformint('e', 1, 10),\n",
    "    'm': hp.uniform('m', 0, 0.9) # GB: Default: 0(pytorch)-0.9.\n",
    "}\n",
    "\n",
    "best = fmin(fn=run_model,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10)\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "782be9af",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 22\u001b[0m\n\u001b[1;32m     17\u001b[0m             class_total[label] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m): \u001b[38;5;66;03m# GB: Also 20? Changed from 10 to 20, trying...\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy of \u001b[39m\u001b[38;5;132;01m%5s\u001b[39;00m\u001b[38;5;124m : \u001b[39m\u001b[38;5;132;01m%2d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m---> 22\u001b[0m         classes[i], \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m class_correct[i] \u001b[38;5;241m/\u001b[39m (class_total[i]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.001\u001b[39m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classes' is not defined"
     ]
    }
   ],
   "source": [
    "# GB: Make function to work on either train or test:\n",
    "# GB: Numerator/Denominator:\n",
    "class_correct = list(0. for i in range(20)) # GB: Also 20? Changed from 10 to 20, trying...\n",
    "class_total = list(0. for i in range(20)) # GB: Also 20? Changed from 10 to 20, trying...\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4): # GB: Changed from 4 to , doesn't work past 2. # GB: Batch remainer of 2 not 4\n",
    "            # GB: Temp fix:\n",
    "            if len(labels) < 4:\n",
    "                break\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(4): # GB: Also 20? Changed from 10 to 20, trying...\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / (class_total[i]+0.001))) # GB: quick fix stop div 0\n",
    "    \n",
    "# GB: Learning rate 0.001:\n",
    "\n",
    "# GB: Learning rate 0.1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67424eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB: Make function to work on either train or test:\n",
    "# GB: Tried with train, not very good on self either?\n",
    "# GB: Numerator/Denominator:\n",
    "class_correct = list(0. for i in range(4)) # GB: Also 20? Changed from 10 to 20, trying...\n",
    "class_total = list(0. for i in range(4)) # GB: Also 20? Changed from 10 to 20, trying...\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4): # GB: Changed from 4 to , doesn't work past 2. # GB: Batch remainer of 2 not 4\n",
    "            # GB: Temp fix:\n",
    "            if len(labels) < 4:\n",
    "                break\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(4): # GB: Also 20? Changed from 10 to 20, trying...\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / (class_total[i]+0.001))) # GB: quick fix stop div 0\n",
    "    \n",
    "# GB: Learning rate 0.001:\n",
    "\n",
    "# GB: Learning rate 0.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03baa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB: Switches:\n",
    "# GB: out_channels to in_channels 10 seems to be better than 6.\n",
    "# GB: Higher resolutions appear to get worse.\n",
    "\n",
    "# GB: Strategy:\n",
    "# GB: Poor results on initial class.\n",
    "# GB: Try 'expressions' a little better but not convincing.\n",
    "# GB: Try Mitchell vs not Mitchell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae25a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB: There are too many potential dead ends for this to be a useful exercise.\n",
    "# GB: Also too many unknowns due to lack of instruction.\n",
    "# GB: It should have kept the original dataset unchanged and made the exercise to wrap the model, not both.\n",
    "# GB: Changing both simultaniously is likely to cause errors and waste significant amounts of time.\n",
    "# GB: Too much refactoring!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fd2f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB: Ref.: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "# GB: Save and load models?\n",
    "# GB: From Ref. and specifically bookmark above, trying..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB: Forked in from Ref.: https://pytorch.org/tutorials/beginner/saving_loading_models.html:\n",
    "\n",
    "# GB: Changed from TheModelClass to Net.\n",
    "# GB: Changed from model to net.\n",
    "# GB: No change to optimizer.\n",
    "\n",
    "# Define model, see cell above.\n",
    "# GB: class TheModelClass(nn.Module): # GB: Net.\n",
    "    # GB: ...\n",
    "\n",
    "# Initialize model\n",
    "# GB: model = TheModelClass() # GB: net.\n",
    "\n",
    "# Initialize optimizer\n",
    "# GB: optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # GB: optimimizer.\n",
    "\n",
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in net.state_dict():\n",
    "    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "\n",
    "# GB: Output: # GB: ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b33e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB: Same Ref.: #saving-loading-model-for-inference\n",
    "path = './models/pytorch-model-2024-05-13.pth'\n",
    "torch.save(net.state_dict(), path) # GB: Changed from PATH to path.\n",
    "# GB: NB Create folder first. ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216f6bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(*args, **kwargs) # GB: Changed from TheModelClass to Net. Used model to keep separate form net.\n",
    "model.load_state_dict(torch.load(path)) # GB: Changed from PATH to path.\n",
    "model.eval()\n",
    "# GB: ok-ish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9069d608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB: Same Ref.: #save-load-entire-model\n",
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model class must be defined somewhere\n",
    "model = torch.load(PATH)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be8ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB: Same Ref.: #export-load-model-in-torchscript-format\n",
    "# GB: Skipped for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB: Same Ref.: #saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training\n",
    "# GB: Save:\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            ...\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b373ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB: Load:\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "# - or -\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0430ac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB: Same Ref.: #save-load-entire-model\n",
    "# GB: Assumed that the section before is sufficient, i.e. for a single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adb1f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB: Spare:\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5 # unnormalize # GB: Reverse z = (x - mean) / sd.\n",
    "    npimg = img.numpy() # GB: Converts a tensor object into an numpy.ndarray object.\n",
    "    # GB: print(npimg) # GB: Added.\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    # GB: In PyTorch, the order of the dimensions is channel*width*height.\n",
    "    # GB: In Matplotlib, the order of the dimensions is width*height*channel.\n",
    "    # GB: That’s why the transpose is needed.\n",
    "    # GB: Ref.: https://discuss.pytorch.org/t/trying-to-understand-torch-transpose/5656\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "# GB: Ref.: https://stackoverflow.com/questions/74289077/attributeerror-multiprocessingdataloaderiter-object-has-no-attribute-next\n",
    "dataiter = iter(trainset_2) # GB: Changed from trainloader to data to trainset, forked in point.\n",
    "images, labels = next(dataiter) # GB: Changed from dataiter.next() to data = next(dataiter).\n",
    "# GB: images = just 1, labels = just 1 in this case.\n",
    "# GB: Ref.: https://www.w3schools.com/python/ref_func_iter.asp\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# GB: images, labels = next(dataiter)\n",
    "# GB: imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# print labels\n",
    "# GB: print(' '.join('%5s' % classes[labels[j]] for j in range(4))) # GB: Loader is no longer in batches of 4.\n",
    "# GB: EDA:\n",
    "print(len(data)) # GB: Not 640 * 3 (1920).\n",
    "print(labels) # GB: \n",
    "print(classes[labels]) # GB: Seems ok.\n",
    "print(images.numpy().size) # GB: Resolution(s).\n",
    "print(images.numpy().shape) # GB: Resolution(s).\n",
    "# GB: .img attribute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b865a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB: Train set, changed from CIFAR10 to FashionMNIST:\n",
    "#trainset = torchvision.datasets.FashionMNIST(root='./data/fashion-mnist', train=True,\n",
    "#                                        download=True, transform=transform)\n",
    "#trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, #GB: Try 1 instead of 4.\n",
    "#                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# GB: Test set, changed from CIFAR10 to FashionMNIST:\n",
    "#testset = torchvision.datasets.FashionMNIST(root='./data/fashion-mnist', train=False,\n",
    "#                                       download=True, transform=transform)\n",
    "#testloader = torch.utils.data.DataLoader(testset, batch_size=4, # GB: Try 1 instead of 4.\n",
    "#                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58afd78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB: Probably not needed:\n",
    "#trainloader_1 = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "#testloader_1 = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=2)\n",
    "#trainloader_2 = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "#testloader_2 = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=2)\n",
    "#trainloader_4 = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "#testloader_4 = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe442df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask = np.isin(element, test_elements, invert=True)\n",
    "#arr = np.delete(arr, indexes, axis=0)\n",
    "# GB: Alt option by index m = (arr[:, None] != X_y_train).all(-1).any(1) # Filter A that are present in B\n",
    "# Alt option x is your dataset\n",
    "#x = numpy.random.rand(100, 5)\n",
    "#indices = numpy.random.permutation(x.shape[0])\n",
    "#training_idx, test_idx = indices[:80], indices[80:]\n",
    "#training, test = x[training_idx,:], x[test_idx,:]\n",
    "# Alt, alt , option\n",
    "# construct the full dataset\n",
    "#dataset = ImageFolder(\"image-folders\",...)\n",
    "# select the indices of all other folders\n",
    "#idx = [i for i in range(len(dataset)) if dataset.imgs[i][1] != dataset.class_to_idx['class_s']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd1970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB: class Net(nn.Module):\n",
    "# GB:    def __init__(self):\n",
    "# GB:       pass # GB: The pass statement is used as a placeholder for future code.\n",
    "# GB:\n",
    "# GB:    def forward(self, x):\n",
    "# GB:        pass # GB: The pass statement is used as a placeholder for future code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71010d8",
   "metadata": {},
   "source": [
    "## References:\n",
    "1. https://www.geeksforgeeks.org/args-kwargs-python/\n",
    "1. https://discuss.pytorch.org/t/hyperparameter-tuning-using-bayesian-optimization/36145/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d043f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
